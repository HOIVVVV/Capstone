import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image

# âœ… 1. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (ì›ì²œë°ì´í„° í´ë” ê²½ë¡œ ë°˜ì˜)
class CustomDataset(Dataset):
    def __init__(self, json_path, img_root_dir, transform=None):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        self.img_root_dir = img_root_dir
        self.transform = transform
        self.images = {img["id"]: img for img in data["images"]}
        self.annotations = {ann["image_id"]: ann for ann in data["annotations"]}

        # ì¹´í…Œê³ ë¦¬ IDë¥¼ ë¼ë²¨ë¡œ ë§¤í•‘
        self.category_map = {ann["category_id"] for ann in data["annotations"]}
        self.category_map = {cat_id: i for i, cat_id in enumerate(sorted(self.category_map))}

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_info = self.images[idx + 1]
        ann_info = self.annotations.get(img_info["id"], {})

        # ì´ë¯¸ì§€ ê²½ë¡œ êµ¬ì„± (ì›ì²œë°ì´í„° í´ë” êµ¬ì¡° ë°˜ì˜)
        img_path = img_info["file_path"]
        image = Image.open(img_path).convert("RGB")

        # ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
        category_id = ann_info.get("category_id", 0)
        label = self.category_map.get(category_id, 0)  # ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ 0

        # ë°”ìš´ë”© ë°•ìŠ¤ (í•„ìš”í•˜ë©´ ì‚¬ìš©)
        bbox = ann_info.get("bbox", [0, 0, 0, 0])

        # ë³€í™˜ ì ìš©
        if self.transform:
            image = self.transform(image)

        return image, label, torch.tensor(bbox, dtype=torch.float32)

# âœ… 2. ë°ì´í„° ë³€í™˜ (ResNeXt ì…ë ¥ í¬ê¸° ë§ì¶”ê¸°)
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ResNeXt ì…ë ¥ í¬ê¸°
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# âœ… 3. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
dataset = CustomDataset("merged_annotations.json", "ì›ì²œë°ì´í„°", transform=transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# âœ… 4. ResNeXt ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ìˆ˜ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")

model = models.resnext50_32x4d(pretrained=True)  # ResNeXt50-32x4d ì‚¬ìš©
num_classes = 10  # í´ë˜ìŠ¤ ê°œìˆ˜ (í™•ì¸ í•„ìš”)
model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)  # ë§ˆì§€ë§‰ ë ˆì´ì–´ ìˆ˜ì •
model = model.to(device)

# âœ… 5. ì†ì‹¤ í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# âœ… 6. í•™ìŠµ ë£¨í”„
num_epochs = 10  # í•™ìŠµ ì—í¬í¬ ìˆ˜

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels, _ in dataloader:  # ë°”ìš´ë”© ë°•ìŠ¤ëŠ” ì‚¬ìš© ì•ˆ í•¨
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}")

print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")

# âœ… 7. ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "resnext_model.pth")
print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: resnext_model.pth")
