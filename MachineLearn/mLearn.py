import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image

# âœ… 1. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (Class_codeë¡œ ë¼ë²¨ë§)
class CustomDataset(Dataset):
    def __init__(self, json_path, img_root_dir, transform=None):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        self.img_root_dir = img_root_dir
        self.transform = transform
        self.images = {img["id"]: img for img in data["images"]}
        self.annotations = {ann["image_id"]: ann for ann in data["annotations"]}

        # âœ… ëª¨ë“  Class_code ìˆ˜ì§‘í•˜ì—¬ ë¼ë²¨ ë§¤í•‘
        self.class_codes = sorted({ann["attributes"]["Class_code"] for ann in data["annotations"]})
        self.class_code_to_label = {code: i for i, code in enumerate(self.class_codes)}

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_info = self.images[idx + 1]
        ann_info = self.annotations.get(img_info["id"], {})

        # âœ… ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš© (ì‚¬ì „ ìƒì„±ëœ file_path ì‚¬ìš©)
        img_path = img_info["file_path"]
        image = Image.open(img_path).convert("RGB")

        # âœ… ë¼ë²¨: Class_code ê¸°ë°˜
        class_code = ann_info.get("attributes", {}).get("Class_code", "UNKNOWN")
        label = self.class_code_to_label.get(class_code, 0)  # ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´

        # ë°”ìš´ë”© ë°•ìŠ¤ (ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ í¬í•¨)
        bbox = ann_info.get("bbox", [0, 0, 0, 0])

        if self.transform:
            image = self.transform(image)

        return image, label, torch.tensor(bbox, dtype=torch.float32)

# âœ… 2. ë°ì´í„° ë³€í™˜
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ResNeXt ì…ë ¥ í¬ê¸°
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# âœ… 3. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë”
dataset = CustomDataset("merged_annotations.json", "ì›ì²œë°ì´í„°", transform=transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# âœ… 4. ResNeXt ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° ìˆ˜ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")

model = models.resnext50_32x4d(pretrained=True)
num_classes = len(dataset.class_code_to_label)  # Class_code ê°œìˆ˜
model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)
model = model.to(device)

# âœ… 5. ì†ì‹¤ í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# âœ… 6. í•™ìŠµ ë£¨í”„
num_epochs = 10

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels, _ in dataloader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}")

print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")

# âœ… 7. ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "resnext_model.pth")
print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: resnext_model.pth")
